{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cbvjd8gZ770",
        "outputId": "2b735047-00bf-4bcd-a90e-907f238ee4d9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uOY5b94Z9n3",
        "outputId": "8a8f588e-7655-455b-fe3e-e3d8e38b9504"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.99-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.99-py3-none-any.whl (976 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m976.9/976.9 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.99 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-QUVPZSaJWc",
        "outputId": "a6e48321-c9ea-4543-ea8b-ae736856dc5d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRnrpk9JZiBP",
        "outputId": "9b5229c8-9706-434d-9432-c939975c5dda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 165MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolov8-nano: 3.1572 million parameters\n",
            "DetectionModel(\n",
            "  (model): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (2): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): Conv(\n",
            "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (4): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0-1): 2 x Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): Conv(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (6): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0-1): 2 x Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): Conv(\n",
            "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (8): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): SPPF(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (11): Concat()\n",
            "    (12): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (14): Concat()\n",
            "    (15): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (16): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (17): Concat()\n",
            "    (18): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (19): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (20): Concat()\n",
            "    (21): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (22): Detect(\n",
            "      (cv2): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (cv3): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (dfl): DFL(\n",
            "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# import\n",
        "import math, os, random, cv2, numpy, torch\n",
        "import torch.nn as nn\n",
        "#from ultralytics import YOLO\n",
        "\n",
        "# explore the original yolov8 model\n",
        "\n",
        "# original yolov8n\n",
        "model_n=YOLO('yolov8n.pt')\n",
        "print(f\"yolov8-nano: {sum(p.numel() for p in model_n.parameters())/1e6} million parameters\")\n",
        "\n",
        "\n",
        "# model_s=YOLO('yolov8s.pt')\n",
        "# print(f\"yolov8-small: {sum(p.numel() for p in model_s.parameters())/1e6} million parameters\")\n",
        "\n",
        "print(model_n.model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Backbone\n",
        "The backbone is modified CSPDarknet53 which comprises of blocks Conv, C2f, SPPF\n",
        "1. **Conv**: Conv2d + BatchNorm2d + SiLU\n",
        "2. **C2f (cross-stage partial bottleneck with 2 convolutions)**: Conv + Bottlenecks + Conv <br>\n",
        "Combine high-level features with contextual information to improve detection accuracy.\n",
        "3. **SPPF (spatial pyramid pooling fast)**: Conv + Maxpool2d + Conv <br>\n",
        "Process features at various scales and pool them into a fixed-size feature map."
      ],
      "metadata": {
        "id": "3VD0S_tka2KE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a) Conv\n"
      ],
      "metadata": {
        "id": "RIH_iwyUb-wX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv(nn.Module):\n",
        "     def __init__(self,\n",
        "                 in_channels: int,\n",
        "                 out_channels: int,\n",
        "                 kernel_size: int = 3,\n",
        "                 stride: int = 1,\n",
        "                 padding: int = 1,\n",
        "                 groups: int = 1,\n",
        "                 activation: bool = True):\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            in_channels (int): Number of input channels\n",
        "            out_channels (int): Number of output channels\n",
        "            kernel_size (int, optional): Kernel size of the convolution. Defaults to 3.\n",
        "            stride (int, optional): Stride for the convolution. Defaults to 1.\n",
        "            padding (int, optional): Padding for the convolution. Defaults to 1.\n",
        "            groups (int, optional): Number of groups for grouped convolutions. Defaults to 1.\n",
        "            activation (bool, optional): Whether to apply SiLU activation. Defaults to True.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        super().__init__()\n",
        "        self.conv=nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,bias=False,groups=groups)\n",
        "        self.bn=nn.BatchNorm2d(out_channels,eps=0.001,momentum=0.03)\n",
        "        self.act=nn.SiLU(inplace=True) if activation else nn.Identity()\n",
        "\n",
        "def forward(self,x):\n",
        "        return self.act(self.bn(self.conv(x)))"
      ],
      "metadata": {
        "id": "jpz_uh-Aa1yo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "111192fd-34cc-46f8-a35e-2a65bab572b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 28)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    def forward(self,x):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_channels, in_channels // reduction)\n",
        "        self.fc2 = nn.Linear(in_channels // reduction, in_channels)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Squeeze: global average pooling\n",
        "        b, c, _, _ = x.size()\n",
        "        squeeze = F.adaptive_avg_pool2d(x, (1, 1)).view(b, c)\n",
        "\n",
        "        # Excitation: fully connected layers\n",
        "        excitation = F.relu(self.fc1(squeeze))\n",
        "        excitation = self.fc2(excitation)\n",
        "        excitation = self.sigmoid(excitation).view(b, c, 1, 1)\n",
        "\n",
        "        # Recalibration\n",
        "        return x * excitation\n",
        "\n",
        "class Conv(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels: int,\n",
        "                 out_channels: int,\n",
        "                 kernel_size: int = 3,\n",
        "                 stride: int = 1,\n",
        "                 padding: int = 1,\n",
        "                 groups: int = 1,\n",
        "                 activation: bool = True,\n",
        "                 use_dropout: bool = False,\n",
        "                 dropout_prob: float = 0.5,\n",
        "                 batch_norm: bool = True,\n",
        "                 use_se: bool = True):  # Add parameter to toggle SE Block\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            in_channels (int): Number of input channels\n",
        "            out_channels (int): Number of output channels\n",
        "            kernel_size (int): Kernel size of the convolution.\n",
        "            stride (int): Stride for the convolution.\n",
        "            padding (int): Padding for the convolution.\n",
        "            groups (int): Number of groups for grouped convolutions.\n",
        "            activation (bool): Whether to apply activation function (SiLU by default).\n",
        "            use_dropout (bool): Whether to apply dropout.\n",
        "            dropout_prob (float): Dropout probability.\n",
        "            batch_norm (bool): Whether to include batch normalization.\n",
        "            use_se (bool): Whether to apply SE Block for channel attention.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Conv layer\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False, groups=groups)\n",
        "\n",
        "        # Batch normalization\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.03) if batch_norm else nn.Identity()\n",
        "\n",
        "        # Activation layer (SiLU by default)\n",
        "        self.act = nn.SiLU(inplace=True) if activation else nn.Identity()\n",
        "\n",
        "        # Dropout layer (optional)\n",
        "        self.use_dropout = use_dropout\n",
        "        self.dropout = nn.Dropout2d(p=dropout_prob) if use_dropout else nn.Identity()\n",
        "\n",
        "        # Channel Attention (SE Block) layer\n",
        "        self.use_se = SEBlock(out_channels) if use_se else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        # Apply SE Block for Channel Attention (if enabled)\n",
        "        x = self.use_se(x)\n",
        "\n",
        "        # Apply dropout (if enabled)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "nv4fD6NTbFu1"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############nooo\n",
        "class Conv(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels: int,\n",
        "                 out_channels: int,\n",
        "                 kernel_size: int = 3,\n",
        "                 stride: int = 1,\n",
        "                 padding: int = 1,\n",
        "                 groups: int = 1,\n",
        "                 activation: bool = True,\n",
        "                 use_dropout: bool = False,\n",
        "                 dropout_prob: float = 0.5,\n",
        "                 batch_norm: bool = True,\n",
        "                 use_se: bool = True,          # Toggle SE Block\n",
        "                 use_sa: bool = True):          # Toggle Spatial Attention\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            in_channels (int): Number of input channels\n",
        "            out_channels (int): Number of output channels\n",
        "            kernel_size (int): Kernel size of the convolution.\n",
        "            stride (int): Stride for the convolution.\n",
        "            padding (int): Padding for the convolution.\n",
        "            groups (int): Number of groups for grouped convolutions.\n",
        "            activation (bool): Whether to apply activation function (SiLU by default).\n",
        "            use_dropout (bool): Whether to apply dropout.\n",
        "            dropout_prob (float): Dropout probability.\n",
        "            batch_norm (bool): Whether to include batch normalization.\n",
        "            use_se (bool): Whether to apply SE Block for channel attention.\n",
        "            use_sa (bool): Whether to apply Spatial Attention.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Conv layer\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False, groups=groups)\n",
        "\n",
        "        # Batch normalization\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.03) if batch_norm else nn.Identity()\n",
        "\n",
        "        # Activation layer (SiLU by default)\n",
        "        self.act = nn.SiLU(inplace=True) if activation else nn.Identity()\n",
        "\n",
        "        # Dropout layer (optional)\n",
        "        self.use_dropout = use_dropout\n",
        "        self.dropout = nn.Dropout2d(p=dropout_prob) if use_dropout else nn.Identity()\n",
        "\n",
        "        # Channel Attention (SE Block)\n",
        "        self.use_se = SEBlock(out_channels) if use_se else nn.Identity()\n",
        "\n",
        "        # Spatial Attention\n",
        "        self.use_sa = SpatialAttention() if use_sa else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        # Apply Channel Attention (if enabled)\n",
        "        x = self.use_se(x)\n",
        "\n",
        "        # Apply Spatial Attention (if enabled)\n",
        "        x = self.use_sa(x)\n",
        "\n",
        "        # Apply Dropout (if enabled)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "tM4tbGbfnynz"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (b) C2f"
      ],
      "metadata": {
        "id": "_jhcW76IcfIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1 Bottleneck: staack of 2 COnv with shortcut connnection (True/False)\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,shortcut=True):\n",
        "        super().__init__()\n",
        "        self.conv1=Conv(in_channels,out_channels,kernel_size=3,stride=1,padding=1)\n",
        "        self.conv2=Conv(out_channels,out_channels,kernel_size=3,stride=1,padding=1)\n",
        "        self.shortcut=shortcut\n",
        "\n",
        "    def forward(self,x):\n",
        "        x_in=x # for residual connection\n",
        "        x=self.conv1(x)\n",
        "        x=self.conv2(x)\n",
        "        if self.shortcut:\n",
        "            x=x+x_in\n",
        "        return x\n",
        "\n",
        "# 2.2 C2f: Conv + bottleneck*N+ Conv\n",
        "class C2f(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels, num_bottlenecks,shortcut=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mid_channels=out_channels//2\n",
        "        self.num_bottlenecks=num_bottlenecks\n",
        "\n",
        "        self.conv1=Conv(in_channels,out_channels,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "        # sequence of bottleneck layers\n",
        "        self.m=nn.ModuleList([Bottleneck(self.mid_channels,self.mid_channels) for _ in range(num_bottlenecks)])\n",
        "\n",
        "        self.conv2=Conv((num_bottlenecks+2)*out_channels//2,out_channels,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv1(x)\n",
        "\n",
        "        # split x along channel dimension\n",
        "        x1,x2=x[:,:x.shape[1]//2,:,:], x[:,x.shape[1]//2:,:,:]\n",
        "\n",
        "        # list of outputs\n",
        "        outputs=[x1,x2] # x1 is fed through the bottlenecks\n",
        "\n",
        "        for i in range(self.num_bottlenecks):\n",
        "            x1=self.m[i](x1)    # [bs,0.5c_out,w,h]\n",
        "            outputs.insert(0,x1)\n",
        "\n",
        "        outputs=torch.cat(outputs,dim=1) # [bs,0.5c_out(num_bottlenecks+2),w,h]\n",
        "        out=self.conv2(outputs)\n",
        "\n",
        "        return out\n",
        "\n",
        "# sanity check\n",
        "c2f=C2f(in_channels=64,out_channels=128,num_bottlenecks=2)\n",
        "print(f\"{sum(p.numel() for p in c2f.parameters())/1e6} million parameters\")\n",
        "\n",
        "dummy_input=torch.rand((1,64,244,244))\n",
        "dummy_input=c2f(dummy_input)\n",
        "print(\"Output shape: \", dummy_input.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH02qnrvciLU",
        "outputId": "0a82a97d-3f6f-4d7d-f48c-bb4805397b9c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.196128 million parameters\n",
            "Output shape:  torch.Size([1, 128, 244, 244])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (c) SPPF"
      ],
      "metadata": {
        "id": "WyiGuYU4cq9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SPPF(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,kernel_size=5):\n",
        "        #kernel_size= size of maxpool\n",
        "        super().__init__()\n",
        "        hidden_channels=in_channels//2\n",
        "        self.conv1=Conv(in_channels,hidden_channels,kernel_size=1,stride=1,padding=0)\n",
        "        # concatenate outputs of maxpool and feed to conv2\n",
        "        self.conv2=Conv(4*hidden_channels,out_channels,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "        # maxpool is applied at 3 different sacles\n",
        "        self.m=nn.MaxPool2d(kernel_size=kernel_size,stride=1,padding=kernel_size//2,dilation=1,ceil_mode=False)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv1(x)\n",
        "\n",
        "        # apply maxpooling at diffent scales\n",
        "        y1=self.m(x)\n",
        "        y2=self.m(y1)\n",
        "        y3=self.m(y2)\n",
        "\n",
        "        # concantenate\n",
        "        y=torch.cat([x,y1,y2,y3],dim=1)\n",
        "\n",
        "        # final conv\n",
        "        y=self.conv2(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "# sanity check\n",
        "sppf=SPPF(in_channels=128,out_channels=512)\n",
        "print(f\"{sum(p.numel() for p in sppf.parameters())/1e6} million parameters\")\n",
        "\n",
        "dummy_input=sppf(dummy_input)\n",
        "print(\"Output shape: \", dummy_input.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZg47Zjdb36u",
        "outputId": "d2d88ea2-7b67-4624-f103-535eb3feeeb6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.174308 million parameters\n",
            "Output shape:  torch.Size([1, 512, 244, 244])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compiled Backbone**"
      ],
      "metadata": {
        "id": "CxaoUZTkdN9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# backbone = DarkNet53\n",
        "\n",
        "# return d,w,r based on version\n",
        "def yolo_params(version):\n",
        "    if version=='n':\n",
        "        return 1/3,1/4,2.0\n",
        "    elif version=='s':\n",
        "        return 1/3,1/2,2.0\n",
        "    elif version=='m':\n",
        "        return 2/3,3/4,1.5\n",
        "    elif version=='l':\n",
        "        return 1.0,1.0,1.0\n",
        "    elif version=='x':\n",
        "        return 1.0,1.25,1.0\n",
        "\n",
        "class Backbone(nn.Module):\n",
        "    def __init__(self,version,in_channels=3,shortcut=True):\n",
        "        super().__init__()\n",
        "        d,w,r=yolo_params(version)\n",
        "\n",
        "        # conv layers\n",
        "        self.conv_0=Conv(in_channels,int(64*w),kernel_size=3,stride=2,padding=1)\n",
        "        self.conv_1=Conv(int(64*w),int(128*w),kernel_size=3,stride=2,padding=1)\n",
        "        self.conv_3=Conv(int(128*w),int(256*w),kernel_size=3,stride=2,padding=1)\n",
        "        self.conv_5=Conv(int(256*w),int(512*w),kernel_size=3,stride=2,padding=1)\n",
        "        self.conv_7=Conv(int(512*w),int(512*w*r),kernel_size=3,stride=2,padding=1)\n",
        "\n",
        "        # c2f layers\n",
        "        self.c2f_2=C2f(int(128*w),int(128*w),num_bottlenecks=int(3*d),shortcut=True)\n",
        "        self.c2f_4=C2f(int(256*w),int(256*w),num_bottlenecks=int(6*d),shortcut=True)\n",
        "        self.c2f_6=C2f(int(512*w),int(512*w),num_bottlenecks=int(6*d),shortcut=True)\n",
        "        self.c2f_8=C2f(int(512*w*r),int(512*w*r),num_bottlenecks=int(3*d),shortcut=True)\n",
        "\n",
        "        # sppf\n",
        "        self.sppf=SPPF(int(512*w*r),int(512*w*r))\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv_0(x)\n",
        "        x=self.conv_1(x)\n",
        "\n",
        "        x=self.c2f_2(x)\n",
        "\n",
        "        x=self.conv_3(x)\n",
        "\n",
        "        out1=self.c2f_4(x) # keep for output\n",
        "\n",
        "        x=self.conv_5(out1)\n",
        "\n",
        "        out2=self.c2f_6(x) # keep for output\n",
        "\n",
        "        x=self.conv_7(out2)\n",
        "        x=self.c2f_8(x)\n",
        "        out3=self.sppf(x)\n",
        "\n",
        "        return out1,out2,out3\n",
        "\n",
        "print(\"----Nano model -----\")\n",
        "backbone_n=Backbone(version='n')\n",
        "print(f\"{sum(p.numel() for p in backbone_n.parameters())/1e6} million parameters\")\n",
        "\n",
        "print(\"----Small model -----\")\n",
        "backbone_s=Backbone(version='s')\n",
        "print(f\"{sum(p.numel() for p in backbone_s.parameters())/1e6} million parameters\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk9TXX4fb_gM",
        "outputId": "35ff3fa5-4d1d-45ee-b7de-a5e6c9b0b2a3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----Nano model -----\n",
            "1.324957 million parameters\n",
            "----Small model -----\n",
            "5.283578 million parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "x=torch.rand((1,3,640,640))\n",
        "out1,out2,out3=backbone_n(x)\n",
        "print(out1.shape)\n",
        "print(out2.shape)\n",
        "print(out3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHygqbuxdmHU",
        "outputId": "6eb7aa0e-53d9-4478-dbda-259fe8be0c1b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64, 80, 80])\n",
            "torch.Size([1, 128, 40, 40])\n",
            "torch.Size([1, 256, 20, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Neck\n",
        "The neck comprises of Upsample + C2f with\n",
        "\n",
        "**Upsample** = nearest-neighbor interpolation with scale_factor=2. It doesn't have trainable paramaters."
      ],
      "metadata": {
        "id": "7N0X4nHsdvLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the CBAM class\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channel_attention = ChannelAttention(channel, reduction)\n",
        "        self.spatial_attention = SpatialAttention()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.channel_attention(x)\n",
        "        x = self.spatial_attention(x)\n",
        "        return x\n",
        "\n",
        "# Channel Attention module\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.fc1 = nn.Conv2d(channel, channel // reduction, kernel_size=1, stride=1, padding=0)\n",
        "        self.fc2 = nn.Conv2d(channel // reduction, channel, kernel_size=1, stride=1, padding=0)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=[2, 3], keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=2, keepdim=True)\n",
        "        max_out, _ = torch.max(max_out, dim=3, keepdim=True)\n",
        "        out = avg_out + max_out\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return x * out\n",
        "\n",
        "# Spatial Attention module\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size=7, stride=1, padding=3)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
        "        out = self.conv(x_cat)\n",
        "        out = self.sigmoid(out)\n",
        "        return x * out\n",
        "\n",
        "# Upsample (nearest-neighbor interpolation)\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self, scale_factor=2, mode='nearest'):\n",
        "        super().__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.functional.interpolate(x, scale_factor=self.scale_factor, mode=self.mode)\n",
        "\n",
        "# CBAM-integrated Conv\n",
        "class ConvWithCBAM(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels: int,\n",
        "                 out_channels: int,\n",
        "                 kernel_size: int = 3,\n",
        "                 stride: int = 1,\n",
        "                 padding: int = 1,\n",
        "                 use_cbam: bool = True):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.act = nn.SiLU(inplace=True)\n",
        "        self.cbam = CBAM(out_channels) if use_cbam else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "        x = self.cbam(x)  # Apply CBAM to improve attention\n",
        "        return x\n",
        "\n",
        "# Updated Neck with CBAM-integrated Conv layers\n",
        "class Neck(nn.Module):\n",
        "    def __init__(self, version):\n",
        "        super().__init__()\n",
        "        d, w, r = yolo_params(version)\n",
        "\n",
        "        self.up = Upsample()  # No trainable parameters\n",
        "        self.c2f_1 = C2f(in_channels=int(512 * w * (1 + r)), out_channels=int(512 * w), num_bottlenecks=int(3 * d), shortcut=False)\n",
        "        self.c2f_2 = C2f(in_channels=int(768 * w), out_channels=int(256 * w), num_bottlenecks=int(3 * d), shortcut=False)\n",
        "        self.c2f_3 = C2f(in_channels=int(768 * w), out_channels=int(512 * w), num_bottlenecks=int(3 * d), shortcut=False)\n",
        "        self.c2f_4 = C2f(in_channels=int(512 * w * (1 + r)), out_channels=int(512 * w * r), num_bottlenecks=int(3 * d), shortcut=False)\n",
        "\n",
        "        # Using CBAM-integrated Conv layers\n",
        "        self.cv_1 = ConvWithCBAM(in_channels=int(256 * w), out_channels=int(256 * w), kernel_size=3, stride=2, padding=1, use_cbam=True)\n",
        "        self.cv_2 = ConvWithCBAM(in_channels=int(512 * w), out_channels=int(512 * w), kernel_size=3, stride=2, padding=1, use_cbam=True)\n",
        "\n",
        "    def forward(self, x_res_1, x_res_2, x):\n",
        "        res_1 = x  # For residual connection\n",
        "\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, x_res_2], dim=1)\n",
        "\n",
        "        res_2 = self.c2f_1(x)\n",
        "\n",
        "        x = self.up(res_2)\n",
        "        x = torch.cat([x, x_res_1], dim=1)\n",
        "\n",
        "        out_1 = self.c2f_2(x)\n",
        "\n",
        "        x = self.cv_1(out_1)\n",
        "\n",
        "        x = torch.cat([x, res_2], dim=1)\n",
        "        out_2 = self.c2f_3(x)\n",
        "\n",
        "        x = self.cv_2(out_2)\n",
        "\n",
        "        x = torch.cat([x, res_1], dim=1)\n",
        "        out_3 = self.c2f_4(x)\n",
        "\n",
        "        return out_1, out_2, out_3\n",
        "\n",
        "# Sanity Check\n",
        "neck = Neck(version='n')\n",
        "print(f\"Total Parameters: {sum(p.numel() for p in neck.parameters()) / 1e6:.4f} million\")\n",
        "\n",
        "x = torch.rand((1, 3, 640, 640))\n",
        "out1, out2, out3 = Backbone(version='n')(x)\n",
        "out_1, out_2, out_3 = neck(out1, out2, out3)\n",
        "print(\"Output Shapes: \", out_1.shape, out_2.shape, out_3.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u40hZQEko_Vk",
        "outputId": "2da69ef9-5929-4dad-ab0d-dc89548e6438"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 1.0237 million\n",
            "Output Shapes:  torch.Size([1, 64, 80, 80]) torch.Size([1, 128, 40, 40]) torch.Size([1, 256, 20, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################NO\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# SEBlock for Channel Attention\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(in_channels, in_channels // reduction)\n",
        "        self.fc2 = nn.Linear(in_channels // reduction, in_channels)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.global_avg_pool(x).view(b, c)\n",
        "        y = self.fc2(torch.relu(self.fc1(y)))\n",
        "        y = self.sigmoid(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "# Updated Conv layer with optional SEBlock\n",
        "class Conv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, use_se=True):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.act = nn.SiLU(inplace=True)\n",
        "        self.se = SEBlock(out_channels) if use_se else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "        return self.se(x)\n",
        "\n",
        "# Upsample Module (No trainable params)\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self, scale_factor=2, mode='nearest'):\n",
        "        super().__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.functional.interpolate(x, scale_factor=self.scale_factor, mode=self.mode)\n",
        "\n",
        "class Neck(nn.Module):\n",
        "    def __init__(self, version):\n",
        "        super().__init__()\n",
        "        d, w, r = yolo_params(version)\n",
        "\n",
        "        self.up = Upsample()\n",
        "        self.c2f_1 = C2f(in_channels=int(512*w*(1+r)), out_channels=int(512*w), num_bottlenecks=int(3*d))\n",
        "        self.c2f_2 = C2f(in_channels=int(768*w), out_channels=int(256*w), num_bottlenecks=int(3*d))\n",
        "        self.c2f_3 = C2f(in_channels=int(768*w), out_channels=int(512*w), num_bottlenecks=int(3*d))\n",
        "        self.c2f_4 = C2f(in_channels=int(512*w*(1+r)), out_channels=int(512*w*r), num_bottlenecks=int(3*d))\n",
        "\n",
        "        self.cv_1 = Conv(in_channels=int(256*w), out_channels=int(256*w), kernel_size=3, stride=2, padding=1)\n",
        "        self.cv_2 = Conv(in_channels=int(512*w), out_channels=int(512*w), kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x_res_1, x_res_2, x):\n",
        "        res_1 = x\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, x_res_2], dim=1)\n",
        "\n",
        "        res_2 = self.c2f_1(x)\n",
        "\n",
        "        x = self.up(res_2)\n",
        "        x = torch.cat([x, x_res_1], dim=1)\n",
        "\n",
        "        out_1 = self.c2f_2(x)\n",
        "        x = self.cv_1(out_1)\n",
        "\n",
        "        x = torch.cat([x, res_2], dim=1)\n",
        "        out_2 = self.c2f_3(x)\n",
        "\n",
        "        x = self.cv_2(out_2)\n",
        "        x = torch.cat([x, res_1], dim=1)\n",
        "        out_3 = self.c2f_4(x)\n",
        "\n",
        "        return out_1, out_2, out_3\n",
        "\n",
        "# Sanity Check\n",
        "neck = Neck(version='n')\n",
        "print(f\"Total Parameters: {sum(p.numel() for p in neck.parameters())/1e6:.4f} million\")\n",
        "\n",
        "x = torch.rand((1, 3, 640, 640))\n",
        "out1, out2, out3 = Backbone(version='n')(x)\n",
        "out_1, out_2, out_3 = neck(out1, out2, out3)\n",
        "print(\"Output Shapes: \", out_1.shape, out_2.shape, out_3.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bpKqN_umi1k",
        "outputId": "6f7af16e-36aa-4f3a-d5ba-6d756cac3d70"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 1.0235 million\n",
            "Output Shapes:  torch.Size([1, 64, 80, 80]) torch.Size([1, 128, 40, 40]) torch.Size([1, 256, 20, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upsample = nearest-neighbor interpolation with scale_factor=2\n",
        "#            doesn't have trainable paramaters\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self,scale_factor=2,mode='nearest'):\n",
        "        super().__init__()\n",
        "        self.scale_factor=scale_factor\n",
        "        self.mode=mode\n",
        "\n",
        "    def forward(self,x):\n",
        "        return nn.functional.interpolate(x,scale_factor=self.scale_factor,mode=self.mode)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f43R3-R7mJ1R"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ original\n",
        "class Neck(nn.Module):\n",
        "    def __init__(self,version):\n",
        "        super().__init__()\n",
        "        d,w,r=yolo_params(version)\n",
        "\n",
        "        self.up=Upsample() # no trainable parameters\n",
        "        self.c2f_1=C2f(in_channels=int(512*w*(1+r)), out_channels=int(512*w),num_bottlenecks=int(3*d),shortcut=False)\n",
        "        self.c2f_2=C2f(in_channels=int(768*w), out_channels=int(256*w),num_bottlenecks=int(3*d),shortcut=False)\n",
        "        self.c2f_3=C2f(in_channels=int(768*w), out_channels=int(512*w),num_bottlenecks=int(3*d),shortcut=False)\n",
        "        self.c2f_4=C2f(in_channels=int(512*w*(1+r)), out_channels=int(512*w*r),num_bottlenecks=int(3*d),shortcut=False)\n",
        "\n",
        "        self.cv_1=Conv(in_channels=int(256*w),out_channels=int(256*w),kernel_size=3,stride=2, padding=1)\n",
        "        self.cv_2=Conv(in_channels=int(512*w),out_channels=int(512*w),kernel_size=3,stride=2, padding=1)\n",
        "\n",
        "\n",
        "    def forward(self,x_res_1,x_res_2,x):\n",
        "        # x_res_1,x_res_2,x = output of backbone\n",
        "        res_1=x              # for residual connection\n",
        "\n",
        "        x=self.up(x)\n",
        "        x=torch.cat([x,x_res_2],dim=1)\n",
        "\n",
        "        res_2=self.c2f_1(x)  # for residual connection\n",
        "\n",
        "        x=self.up(res_2)\n",
        "        x=torch.cat([x,x_res_1],dim=1)\n",
        "\n",
        "        out_1=self.c2f_2(x)\n",
        "\n",
        "        x=self.cv_1(out_1)\n",
        "\n",
        "        x=torch.cat([x,res_2],dim=1)\n",
        "        out_2=self.c2f_3(x)\n",
        "\n",
        "        x=self.cv_2(out_2)\n",
        "\n",
        "        x=torch.cat([x,res_1],dim=1)\n",
        "        out_3=self.c2f_4(x)\n",
        "\n",
        "        return out_1,out_2,out_3\n",
        "\n",
        "# sanity check\n",
        "neck=Neck(version='n')\n",
        "print(f\"{sum(p.numel() for p in neck.parameters())/1e6} million parameters\")\n",
        "\n",
        "x=torch.rand((1,3,640,640))\n",
        "out1,out2,out3=Backbone(version='n')(x)\n",
        "out_1,out_2,out_3=neck(out1,out2,out3)\n",
        "print(out_1.shape)\n",
        "print(out_2.shape)\n",
        "print(out_3.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inVtNThsdzxt",
        "outputId": "d6e60b20-1488-4a93-afef-1ea54bb5565c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.02348 million parameters\n",
            "torch.Size([1, 64, 80, 80])\n",
            "torch.Size([1, 128, 40, 40])\n",
            "torch.Size([1, 256, 20, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Head\n",
        "Consist of 3 modules: (1) bbox coordinates, (2) classification scores, (3) distribution focal loss (DFL).\n",
        "\n",
        "**DFL** considers the predicted bbox coordinates as a probability distribution. At inference time, it samples from the distribution to get **refined coordinates** $(x,y,w,h)$. For example, to predict coordinate $x$ in the normalized range $[0,1]$:\n",
        "1. DFL uses 16 bins which are equally spaced in $[0,1]$, bin length = 1/16.\n",
        "2. The model outputs 16 numbers which corresponds to probabilities that x falls in these bins, for example, $[0,0,...,9/10,1/10]$.\n",
        "3. Prediction for $x=$ mean value $= 9/10\\cdot15/16+1/10\\cdot 1=0.94375$\n"
      ],
      "metadata": {
        "id": "Rev6xI_Bd4kq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a) DFL"
      ],
      "metadata": {
        "id": "2n-S-UPrd8Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DFL\n",
        "class DFL(nn.Module):\n",
        "    def __init__(self,ch=16):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ch=ch\n",
        "\n",
        "        self.conv=nn.Conv2d(in_channels=ch,out_channels=1,kernel_size=1,bias=False).requires_grad_(False)\n",
        "\n",
        "        # initialize conv with [0,...,ch-1]\n",
        "        x=torch.arange(ch,dtype=torch.float).view(1,ch,1,1)\n",
        "        self.conv.weight.data[:]=torch.nn.Parameter(x) # DFL only has ch parameters\n",
        "\n",
        "    def forward(self,x):\n",
        "        # x must have num_channels = 4*ch: x=[bs,4*ch,c]\n",
        "        b,c,a=x.shape                           # c=4*ch\n",
        "        x=x.view(b,4,self.ch,a).transpose(1,2)  # [bs,ch,4,a]\n",
        "\n",
        "        # take softmax on channel dimension to get distribution probabilities\n",
        "        x=x.softmax(1)                          # [b,ch,4,a]\n",
        "        x=self.conv(x)                          # [b,1,4,a]\n",
        "        return x.view(b,4,a)                    # [b,4,a]\n",
        "\n",
        "# sanity check\n",
        "dummy_input=torch.rand((1,64,128))\n",
        "dfl=DFL()\n",
        "print(f\"{sum(p.numel() for p in dfl.parameters())} parameters\")\n",
        "\n",
        "dummy_output=dfl(dummy_input)\n",
        "print(dummy_output.shape)\n",
        "\n",
        "print(dfl)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN574HWbd5id",
        "outputId": "64255727-5495-4409-889e-e03c7a1d6f9d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 parameters\n",
            "torch.Size([1, 4, 128])\n",
            "DFL(\n",
            "  (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (b) Head"
      ],
      "metadata": {
        "id": "HHQx5u1jeC4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self,version,ch=16,num_classes=80):\n",
        "\n",
        "        super().__init__()\n",
        "        self.ch=ch                          # dfl channels\n",
        "        self.coordinates=self.ch*4          # number of bounding box coordinates\n",
        "        self.nc=num_classes                 # 80 for COCO\n",
        "        self.no=self.coordinates+self.nc    # number of outputs per anchor box\n",
        "\n",
        "        self.stride=torch.zeros(3)          # strides computed during build\n",
        "\n",
        "        d,w,r=yolo_params(version=version)\n",
        "\n",
        "        # for bounding boxes\n",
        "        self.box=nn.ModuleList([\n",
        "            nn.Sequential(Conv(int(256*w),self.coordinates,kernel_size=3,stride=1,padding=1),\n",
        "                          Conv(self.coordinates,self.coordinates,kernel_size=3,stride=1,padding=1),\n",
        "                          nn.Conv2d(self.coordinates,self.coordinates,kernel_size=1,stride=1)),\n",
        "\n",
        "            nn.Sequential(Conv(int(512*w),self.coordinates,kernel_size=3,stride=1,padding=1),\n",
        "                          Conv(self.coordinates,self.coordinates,kernel_size=3,stride=1,padding=1),\n",
        "                          nn.Conv2d(self.coordinates,self.coordinates,kernel_size=1,stride=1)),\n",
        "\n",
        "            nn.Sequential(Conv(int(512*w*r),self.coordinates,kernel_size=3,stride=1,padding=1),\n",
        "                          Conv(self.coordinates,self.coordinates,kernel_size=3,stride=1,padding=1),\n",
        "                          nn.Conv2d(self.coordinates,self.coordinates,kernel_size=1,stride=1))\n",
        "        ])\n",
        "\n",
        "        # for classification\n",
        "        self.cls=nn.ModuleList([\n",
        "            nn.Sequential(Conv(int(256*w),self.nc,kernel_size=3,stride=1,padding=1),\n",
        "                          Conv(self.nc,self.nc,kernel_size=3,stride=1,padding=1),\n",
        "                          nn.Conv2d(self.nc,self.nc,kernel_size=1,stride=1)),\n",
        "\n",
        "            nn.Sequential(Conv(int(512*w),self.nc,kernel_size=3,stride=1,padding=1),\n",
        "                          Conv(self.nc,self.nc,kernel_size=3,stride=1,padding=1),\n",
        "                          nn.Conv2d(self.nc,self.nc,kernel_size=1,stride=1)),\n",
        "\n",
        "            nn.Sequential(Conv(int(512*w*r),self.nc,kernel_size=3,stride=1,padding=1),\n",
        "                          Conv(self.nc,self.nc,kernel_size=3,stride=1,padding=1),\n",
        "                          nn.Conv2d(self.nc,self.nc,kernel_size=1,stride=1))\n",
        "        ])\n",
        "\n",
        "        # dfl\n",
        "        self.dfl=DFL()\n",
        "\n",
        "    def forward(self,x):\n",
        "        # x = output of Neck = list of 3 tensors with different resolution and different channel dim\n",
        "        #     x[0]=[bs, ch0, w0, h0], x[1]=[bs, ch1, w1, h1], x[2]=[bs,ch2, w2, h2]\n",
        "\n",
        "        for i in range(len(self.box)):       # detection head i\n",
        "            box=self.box[i](x[i])            # [bs,num_coordinates,w,h]\n",
        "            cls=self.cls[i](x[i])            # [bs,num_classes,w,h]\n",
        "            x[i]=torch.cat((box,cls),dim=1)  # [bs,num_coordinates+num_classes,w,h]\n",
        "\n",
        "        # in training, no dfl output\n",
        "        if self.training:\n",
        "            return x                         # [3,bs,num_coordinates+num_classes,w,h]\n",
        "\n",
        "        # in inference time, dfl produces refined bounding box coordinates\n",
        "        anchors, strides = (i.transpose(0, 1) for i in self.make_anchors(x, self.stride))\n",
        "\n",
        "        # concatenate predictions from all detection layers\n",
        "        x = torch.cat([i.view(x[0].shape[0], self.no, -1) for i in x], dim=2) #[bs, 4*self.ch + self.nc, sum_i(h[i]w[i])]\n",
        "\n",
        "        # split out predictions for box and cls\n",
        "        #           box=[bs,4×self.ch,sum_i(h[i]w[i])]\n",
        "        #           cls=[bs,self.nc,sum_i(h[i]w[i])]\n",
        "        box, cls = x.split(split_size=(4 * self.ch, self.nc), dim=1)\n",
        "\n",
        "\n",
        "        a, b = self.dfl(box).chunk(2, 1)  # a=b=[bs,2×self.ch,sum_i(h[i]w[i])]\n",
        "        a = anchors.unsqueeze(0) - a\n",
        "        b = anchors.unsqueeze(0) + b\n",
        "        box = torch.cat(tensors=((a + b) / 2, b - a), dim=1)\n",
        "\n",
        "        return torch.cat(tensors=(box * strides, cls.sigmoid()), dim=1)\n",
        "\n",
        "\n",
        "    def make_anchors(self, x, strides, offset=0.5):\n",
        "        # x= list of feature maps: x=[x[0],...,x[N-1]], in our case N= num_detection_heads=3\n",
        "        #                          each having shape [bs,ch,w,h]\n",
        "        #    each feature map x[i] gives output[i] = w*h anchor coordinates + w*h stride values\n",
        "\n",
        "        # strides = list of stride values indicating how much\n",
        "        #           the spatial resolution of the feature map is reduced compared to the original image\n",
        "\n",
        "        assert x is not None\n",
        "        anchor_tensor, stride_tensor = [], []\n",
        "        dtype, device = x[0].dtype, x[0].device\n",
        "        for i, stride in enumerate(strides):\n",
        "            _, _, h, w = x[i].shape\n",
        "            sx = torch.arange(end=w, device=device, dtype=dtype) + offset  # x coordinates of anchor centers\n",
        "            sy = torch.arange(end=h, device=device, dtype=dtype) + offset  # y coordinates of anchor centers\n",
        "            sy, sx = torch.meshgrid(sy, sx)                                # all anchor centers\n",
        "            anchor_tensor.append(torch.stack((sx, sy), -1).view(-1, 2))\n",
        "            stride_tensor.append(torch.full((h * w, 1), stride, dtype=dtype, device=device))\n",
        "        return torch.cat(anchor_tensor), torch.cat(stride_tensor)\n"
      ],
      "metadata": {
        "id": "vIkwj92FeD1E"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "detect=Head(version='n')\n",
        "print(f\"{sum(p.numel() for p in detect.parameters())/1e6} million parameters\")\n",
        "\n",
        "# out_1,out_2,out_3 are output of the neck\n",
        "output=detect([out_1,out_2,out_3])\n",
        "print(output[0].shape)\n",
        "print(output[1].shape)\n",
        "print(output[2].shape)\n",
        "\n",
        "print(detect)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjBgppeTeKf6",
        "outputId": "1bce4262-1ef3-4c38-a953-7d83c115f8a2"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.906454 million parameters\n",
            "torch.Size([1, 144, 80, 80])\n",
            "torch.Size([1, 144, 40, 40])\n",
            "torch.Size([1, 144, 20, 20])\n",
            "Head(\n",
            "  (box): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (cls): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=80, out_features=5, bias=True)\n",
            "          (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=80, out_features=5, bias=True)\n",
            "          (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=80, out_features=5, bias=True)\n",
            "          (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=80, out_features=5, bias=True)\n",
            "          (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=80, out_features=5, bias=True)\n",
            "          (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=80, out_features=5, bias=True)\n",
            "          (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (dfl): DFL(\n",
            "    (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Putting everything together"
      ],
      "metadata": {
        "id": "oJT1lk2peRsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyYolo(nn.Module):\n",
        "    def __init__(self,version):\n",
        "        super().__init__()\n",
        "        self.backbone=Backbone(version=version)\n",
        "        self.neck=Neck(version=version)\n",
        "        self.head=Head(version=version)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.backbone(x)              # return out1,out2,out3\n",
        "        x=self.neck(x[0],x[1],x[2])     # return out_1, out_2,out_3\n",
        "        return self.head(list(x))\n",
        "\n",
        "model=MyYolo(version='n')\n",
        "print(f\"{sum(p.numel() for p in model.parameters())/1e6} million parameters\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJys9EsmeM-F",
        "outputId": "e3edb45d-b37e-46b4-c9fa-9abab820f1e6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.255089 million parameters\n",
            "MyYolo(\n",
            "  (backbone): Backbone(\n",
            "    (conv_0): Conv(\n",
            "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "      (dropout): Identity()\n",
            "      (use_se): SEBlock(\n",
            "        (fc1): Linear(in_features=16, out_features=1, bias=True)\n",
            "        (fc2): Linear(in_features=1, out_features=16, bias=True)\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (conv_1): Conv(\n",
            "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "      (dropout): Identity()\n",
            "      (use_se): SEBlock(\n",
            "        (fc1): Linear(in_features=32, out_features=2, bias=True)\n",
            "        (fc2): Linear(in_features=2, out_features=32, bias=True)\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (conv_3): Conv(\n",
            "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "      (dropout): Identity()\n",
            "      (use_se): SEBlock(\n",
            "        (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "        (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (conv_5): Conv(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "      (dropout): Identity()\n",
            "      (use_se): SEBlock(\n",
            "        (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (conv_7): Conv(\n",
            "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "      (dropout): Identity()\n",
            "      (use_se): SEBlock(\n",
            "        (fc1): Linear(in_features=256, out_features=16, bias=True)\n",
            "        (fc2): Linear(in_features=16, out_features=256, bias=True)\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (c2f_2): C2f(\n",
            "      (conv1): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=32, out_features=2, bias=True)\n",
            "          (fc2): Linear(in_features=2, out_features=32, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv(\n",
            "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=16, out_features=1, bias=True)\n",
            "              (fc2): Linear(in_features=1, out_features=16, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (conv2): Conv(\n",
            "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=16, out_features=1, bias=True)\n",
            "              (fc2): Linear(in_features=1, out_features=16, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (conv2): Conv(\n",
            "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=32, out_features=2, bias=True)\n",
            "          (fc2): Linear(in_features=2, out_features=32, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (c2f_4): C2f(\n",
            "      (conv1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0-1): 2 x Bottleneck(\n",
            "          (conv1): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=32, out_features=2, bias=True)\n",
            "              (fc2): Linear(in_features=2, out_features=32, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (conv2): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=32, out_features=2, bias=True)\n",
            "              (fc2): Linear(in_features=2, out_features=32, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (conv2): Conv(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (c2f_6): C2f(\n",
            "      (conv1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "          (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0-1): 2 x Bottleneck(\n",
            "          (conv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "              (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (conv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "              (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (conv2): Conv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "          (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (c2f_8): C2f(\n",
            "      (conv1): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=256, out_features=16, bias=True)\n",
            "          (fc2): Linear(in_features=16, out_features=256, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "              (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (conv2): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "              (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (conv2): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=256, out_features=16, bias=True)\n",
            "          (fc2): Linear(in_features=16, out_features=256, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (sppf): SPPF(\n",
            "      (conv1): Conv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "          (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (conv2): Conv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=256, out_features=16, bias=True)\n",
            "          (fc2): Linear(in_features=16, out_features=256, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (neck): Neck(\n",
            "    (up): Upsample()\n",
            "    (c2f_1): C2f(\n",
            "      (conv1): Conv(\n",
            "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "          (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "              (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (conv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "              (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (conv2): Conv(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "          (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (c2f_2): C2f(\n",
            "      (conv1): Conv(\n",
            "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=32, out_features=2, bias=True)\n",
            "              (fc2): Linear(in_features=2, out_features=32, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (conv2): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=32, out_features=2, bias=True)\n",
            "              (fc2): Linear(in_features=2, out_features=32, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (conv2): Conv(\n",
            "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "          (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (c2f_3): C2f(\n",
            "      (conv1): Conv(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "          (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "              (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (conv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "              (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (conv2): Conv(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "          (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (c2f_4): C2f(\n",
            "      (conv1): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=256, out_features=16, bias=True)\n",
            "          (fc2): Linear(in_features=16, out_features=256, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "              (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (conv2): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "            (dropout): Identity()\n",
            "            (use_se): SEBlock(\n",
            "              (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "              (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (conv2): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "        (dropout): Identity()\n",
            "        (use_se): SEBlock(\n",
            "          (fc1): Linear(in_features=256, out_features=16, bias=True)\n",
            "          (fc2): Linear(in_features=16, out_features=256, bias=True)\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cv_1): ConvWithCBAM(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "      (cbam): CBAM(\n",
            "        (channel_attention): ChannelAttention(\n",
            "          (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "        (spatial_attention): SpatialAttention(\n",
            "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cv_2): ConvWithCBAM(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "      (cbam): CBAM(\n",
            "        (channel_attention): ChannelAttention(\n",
            "          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "        (spatial_attention): SpatialAttention(\n",
            "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "          (sigmoid): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): Head(\n",
            "    (box): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "          (dropout): Identity()\n",
            "          (use_se): SEBlock(\n",
            "            (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "            (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "            (sigmoid): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "          (dropout): Identity()\n",
            "          (use_se): SEBlock(\n",
            "            (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "            (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "            (sigmoid): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "          (dropout): Identity()\n",
            "          (use_se): SEBlock(\n",
            "            (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "            (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "            (sigmoid): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "          (dropout): Identity()\n",
            "          (use_se): SEBlock(\n",
            "            (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "            (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "            (sigmoid): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "          (dropout): Identity()\n",
            "          (use_se): SEBlock(\n",
            "            (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "            (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "            (sigmoid): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "          (dropout): Identity()\n",
            "          (use_se): SEBlock(\n",
            "            (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "            (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "            (sigmoid): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (cls): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "          (dropout): Identity()\n",
            "          (use_se): SEBlock(\n",
            "            (fc1): Linear(in_features=80, out_features=5, bias=True)\n",
            "            (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
            "            (sigmoid): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "          (dropout): Identity()\n",
            "          (use_se): SEBlock(\n",
            "            (fc1): Linear(in_features=80, out_features=5, bias=True)\n",
            "            (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
            "            (sigmoid): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "          (dropout): Identity()\n",
            "          (use_se): SEBlock(\n",
            "            (fc1): Linear(in_features=80, out_features=5, bias=True)\n",
            "            (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
            "            (sigmoid): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "          (dropout): Identity()\n",
            "          (use_se): SEBlock(\n",
            "            (fc1): Linear(in_features=80, out_features=5, bias=True)\n",
            "            (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
            "            (sigmoid): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "          (dropout): Identity()\n",
            "          (use_se): SEBlock(\n",
            "            (fc1): Linear(in_features=80, out_features=5, bias=True)\n",
            "            (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
            "            (sigmoid): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "          (dropout): Identity()\n",
            "          (use_se): SEBlock(\n",
            "            (fc1): Linear(in_features=80, out_features=5, bias=True)\n",
            "            (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
            "            (sigmoid): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (dfl): DFL(\n",
            "      (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Dataset and Train\n",
        "Due to computation constraint, we will only overfit 1 batch of data from YOLO2017. The loss in yolov8 consists  (1) box_loss, (2) classification_loss, (3) dfl_loss\n",
        "1. **Box loss**: on bounding box coordinates\n",
        "2. **Classification loss**: on classification logits\n",
        "3. **DFL_Loss**: itegrated in box loss\n",
        "\n",
        "**How DFL loss works?**\n",
        "1. Target distribution = single value over 16 bins, this value will be smooth between 2 bin centers. For example, if target value is in the middle of bin 1 and 2, target distribution $= [1/2,1/2,0,...,0]$\n",
        "2. Predicted distribution is based on the output of bbox coordinates. These outputs can be used to compute the probabilities for each bin, say $[1/16,1/16,...,1/16]$\n",
        "3. DFL = cross entropy between prediction and target\n",
        "\n",
        "The utils file for computing loss is taken from https://github.com/jahongir7174/YOLOv8-dfl/tree/master"
      ],
      "metadata": {
        "id": "9hNpcrSseZMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utils\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1pINMrwe0Xo",
        "outputId": "216cf8d4-a9db-4f89-a9db-a85508c07217"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting utils\n",
            "  Downloading utils-1.0.2.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: utils\n",
            "  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13906 sha256=310c83484ad1ee04c83cb668ef3048620ec1a2b7085b995e63f6d36fdaf2b5a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/0c/b3/674aea8c5d91c642c817d4d630bd58faa316724b136844094d\n",
            "Successfully built utils\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision pyyaml ultralytics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9Z5N0uYg1O3",
        "outputId": "d06d44c4-6de3-4c6d-e740-1baa5ddebe54"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"../content/drive/MyDrive/NewMoney_dataset\""
      ],
      "metadata": {
        "id": "yMP510VPhwx9"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "import torch\n",
        "\n",
        "# ===============================\n",
        "# 🚀 STEP 3: Load data.yaml\n",
        "# ===============================\n",
        "yaml_path = os.path.join(dataset_path, \"data.yaml\")  # Path to data.yaml\n",
        "\n",
        "# Read the YAML file\n",
        "with open(yaml_path, \"r\") as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "# Extract dataset paths\n",
        "train_path = data_config[\"train\"]  # Training dataset\n",
        "val_path = data_config[\"val\"]      # Validation dataset\n",
        "num_classes = len(data_config[\"names\"])  # Get the number of classes\n",
        "\n",
        "print(\"✅ Train dataset:\", train_path)\n",
        "print(\"✅ Validation dataset:\", val_path)\n",
        "print(\"✅ Number of classes:\", num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XARuabzkiCSH",
        "outputId": "6cbad791-9555-4dd1-d91b-42f4e445c434"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train dataset: train/images\n",
            "✅ Validation dataset: valid/images\n",
            "✅ Number of classes: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 🚀 STEP 4: Train the Model & Save Results\n",
        "# ===============================\n",
        "output_dir = \"/content/drive/My Drive/YOLOSource_Training_Results\"  # Change to your desired folder\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")  # Load YOLOv8 Nano model\n",
        "\n",
        "model.train(\n",
        "    data=yaml_path,   # Use data.yaml\n",
        "    epochs=50,         # 🔹 Set the number of epochs\n",
        "    batch=16,         # 🔹 Adjust batch size if needed\n",
        "    imgsz=640,        # Image size\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",  # Use GPU if available\n",
        "    project=output_dir,  # 🔹 Save results here\n",
        "    name=\"run1\"        # 🔹 Change for different runs (run1, run2, etc.)\n",
        ")\n",
        "\n",
        "print(f\"🎯 Training complete! Results saved in: {output_dir}/run1\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MbWPGBQjcjo",
        "outputId": "a1673c29-eb4c-4e8e-9eab-bba9d081b6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.99 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=../content/drive/MyDrive/NewMoney_dataset/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=/content/drive/My Drive/YOLOSource_Training_Results, name=run1, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/My Drive/YOLOSource_Training_Results/run1\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 103MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,012,408 parameters, 3,012,392 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/My Drive/YOLOSource_Training_Results/run1', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 292MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/NewMoney_dataset/train/labels.cache... 2163 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2163/2163 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/NewMoney_dataset/valid/labels.cache... 616 images, 0 backgrounds, 0 corrupt: 100%|██████████| 616/616 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/My Drive/YOLOSource_Training_Results/run1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/My Drive/YOLOSource_Training_Results/run1\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      2.03G       1.13      3.631      1.551         52        640:   9%|▉         | 12/136 [02:17<15:02,  7.28s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "import torch\n",
        "\n",
        "# ===============================\n",
        "# 🚀 STEP 3: Load data.yaml and define hyperparameters\n",
        "# ===============================\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = \"path/to/your/dataset\"  # Change this to your dataset directory\n",
        "yaml_path = os.path.join(dataset_path, \"data.yaml\")  # Path to data.yaml\n",
        "\n",
        "# Read the data.yaml file\n",
        "with open(yaml_path, \"r\") as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "# Extract dataset paths and classes\n",
        "train_path = data_config[\"train\"]\n",
        "val_path = data_config[\"val\"]\n",
        "num_classes = len(data_config[\"names\"])\n",
        "\n",
        "# ✅ Define hyperparameters directly in the code\n",
        "hyp_config = {\n",
        "    \"lr0\": 0.01,            # Initial learning rate\n",
        "    \"lrf\": 0.2,             # Final learning rate (lr0 * lrf)\n",
        "    \"momentum\": 0.937,      # SGD momentum\n",
        "    \"weight_decay\": 0.0005, # Optimizer weight decay\n",
        "    \"warmup_epochs\": 3.0,   # Warmup period\n",
        "    \"warmup_momentum\": 0.8, # Warmup initial momentum\n",
        "    \"warmup_bias_lr\": 0.1,  # Warmup initial bias learning rate\n",
        "\n",
        "    # Augmentation Hyperparameters\n",
        "    \"degrees\": 0.0,\n",
        "    \"translate\": 0.1,\n",
        "    \"scale\": 0.5,\n",
        "    \"shear\": 0.0,\n",
        "    \"flipud\": 0.0,\n",
        "    \"fliplr\": 0.5,\n",
        "    \"mosaic\": 1.0,\n",
        "    \"mixup\": 0.0,\n",
        "}\n",
        "\n",
        "# Print loaded data and hyperparameters\n",
        "print(\"✅ Train dataset:\", train_path)\n",
        "print(\"✅ Validation dataset:\", val_path)\n",
        "print(\"✅ Number of classes:\", num_classes)\n",
        "print(\"✅ Loaded Hyperparameters:\", hyp_config)\n"
      ],
      "metadata": {
        "id": "0-mD9HcLq7gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch=next(iter(train_loader))\n",
        "print(\"All keys in batch      : \", batch[1].keys())\n",
        "print(f\"Input batch shape      : \", batch[0].shape)\n",
        "print(f\"Classification scores  : {batch[1]['cls'].shape}\")\n",
        "print(f\"Box coordinates        : {batch[1]['box'].shape}\")\n",
        "print(f\"Index identifier (which score belongs to which image): {batch[1]['idx'].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "i2_qG9AIkA_l",
        "outputId": "e0199634-2c0f-4c2d-f9d2-f4966c966ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-5c6cf2e7a15e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All keys in batch      : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Input batch shape      : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Classification scores  : {batch[1]['cls'].shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Box coordinates        : {batch[1]['box'].shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import util\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# model, loss and optimizer\n",
        "model=MyYolo(version='n')\n",
        "print(f\"{sum(p.numel() for p in model.parameters())/1e6} million parameters\")\n",
        "\n",
        "criterion=util.ComputeLoss(model, params)\n",
        "optimizer=torch.optim.AdamW(model.parameters(), lr=0.5)\n",
        "\n",
        "num_epochs=5\n",
        "\n",
        "imgs,targets=batch[0],batch[1]\n",
        "imgs=imgs.float()\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    outputs=model(imgs)\n",
        "    loss=sum(criterion(outputs,targets)) # cls_loss+box_loss+dfl_loss\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch : {epoch} | loss : {loss.item()}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yIBmwzEEl0dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M4tA8UiWjcFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from utils.dataset import *\n",
        "from torch.utils import data\n",
        "\n",
        "# get all file names\n",
        "data_dir= 'COCO'\n",
        "filenames_train = []\n",
        "with open(f'{data_dir}/train2017.txt') as reader:\n",
        "    for filename in reader.readlines():\n",
        "        filename = os.path.basename(filename.rstrip())\n",
        "        filenames_train.append(f'{data_dir}/images/train2017/' + filename)\n",
        "\n",
        "# input_size for the model\n",
        "input_size=640\n",
        "\n",
        "# get params from yaml file\n",
        "with open('utils/args.yaml', errors='ignore') as f:\n",
        "        params = yaml.safe_load(f)\n",
        "\n",
        "train_data=Dataset(filenames_train,input_size,params,augment=True)\n",
        "train_loader = data.DataLoader(train_data, batch_size=64, num_workers=0, pin_memory=True, collate_fn=Dataset.collate_fn)\n",
        "print(f\"Train_loader : {len(train_loader)} batches\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "A2KMmQX5eYgM",
        "outputId": "58e3d003-8a77-4a4f-96a1-8bada5e82215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'utils.dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-58e2bca3ac2b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# get all file names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.dataset'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}